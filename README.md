# Optimization Different Algorithm

## Summary:
In this project, we first create 3 random functions and investigate if they are convex or concave by plotting them. Then by using different algorithms we find the optimum point and investigate which algorithm works better for the convex/concave function. 

## Optimization Algorithm:
1. Gradient Descent: Minimize a function's value by iteratively adjusting a starting point in the direction of the steepest descent, aiming to find the local or global minimum.
2. Newton-Raphson: Utilize the second derivative of a function to iteratively refine an initial guess, converging towards a local minimum for convex functions or saddle points for non-convex ones.
3. Simulated Annealing: Simulate a physical process of cooling and reheating to explore the solution space, allowing the algorithm to escape local optima in search of a global minimum for complex, non-convex functions.
